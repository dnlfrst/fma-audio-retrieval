{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mmr': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ce539a60f45d94af71af3475e139bc0912b109af7aa64cb512d0be2b18e392ba"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from utils import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "data_path = 'data'\n",
    "fma_small_path = f'{data_path}/fma_small'\n",
    "fma_meta_path = f'{data_path}/fma_metadata'"
   ]
  },
  {
   "source": [
    "# Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = get_all_audio_paths(fma_small_path)\n",
    "\n",
    "# Filter out features for small\n",
    "\n",
    "# features = fma_load(f'{fma_meta_path}/features.csv')\n",
    "# tracks = fma_load(f'{fma_meta_path}/tracks.csv')\n",
    "# genres = fma_load(f'{fma_meta_path}/genres.csv')\n",
    "# echonest = fma_load(f'{fma_meta_path}/echonest.csv')\n",
    "\n",
    "# small = tracks['set', 'subset'] <= 'small'\n",
    "# features_small = features.loc[small]\n",
    "# features_small.to_csv('data/features_small.csv')\n",
    "# tracks_small = tracks.loc[small]\n",
    "# tracks_small.to_csv('data/tracks_small.csv')\n",
    "# genres_small = genres.loc[small]\n",
    "# genres_small.to_csv('data/genres_small.csv')\n",
    "# echonest_small = echonest.loc[small]\n",
    "# echonest_small.to_csv('data/echonest_small.csv')\n",
    "\n",
    "features = fma_load(f'{data_path}/features_small.csv')\n",
    "tracks = fma_load(f'{data_path}/tracks_small.csv')"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = skl.utils.shuffle(features, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(features)\n",
    "\n",
    "i_to_id = features.index\n",
    "with open(f'{data_path}/i_to_id.pkl', 'wb') as f:\n",
    "    pickle.dump(i_to_id, f)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=11, algorithm='auto').fit(features)\n",
    "with open(f'{data_path}/all_features_nn.pkl', 'wb') as f:\n",
    "    pickle.dump(nbrs, f)"
   ]
  },
  {
   "source": [
    "# Query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query one song\n",
    "tid = 121346\n",
    "audio_feature = features[features.index == tid]\n",
    "distances, indices = nbrs.kneighbors(audio_feature)\n",
    "print(audio_feature.index)\n",
    "print([str(e) for e in i_to_id[indices[0]]])\n",
    "sns.lineplot(x=[str(e) for e in i_to_id[indices[0]]], y=distances[0])\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('distance')\n",
    "# ['121346', '130986', '48492', '1680', '70174', '145708', '127286', '154414', '145653', '127193', '1685']\n",
    "# ['121346', '22472', '22473', '121317', '37538', '121322', '9152', '56496', '49039', '86415', '142092']"
   ]
  },
  {
   "source": [
    "# Tempo / Beats Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = get_all_audio_paths(fma_small_path)\n",
    "\n",
    "def compute_beats_features(path):\n",
    "\n",
    "    def tid_from_path(p):\n",
    "        return p.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    def feature_stat(name, values):\n",
    "        if len(values) == 0:\n",
    "            features[f'{name}_mean'] = 0\n",
    "            features[f'{name}_std'] = 0\n",
    "            # features[f'{name}_skew'] = 0\n",
    "            # features[f'{name}_kurtosis'] = 0\n",
    "            features[f'{name}_median'] = 0\n",
    "            features[f'{name}_min'] = 0\n",
    "            features[f'{name}_max'] = 0\n",
    "        else:\n",
    "            features[f'{name}_mean'] = np.mean(values)\n",
    "            features[f'{name}_std'] = np.std(values)\n",
    "            # features[f'{name}_skew'] = stats.skew(values)\n",
    "            # features[f'{name}_kurtosis'] = stats.kurtosis(values)\n",
    "            features[f'{name}_median'] = np.median(values)\n",
    "            features[f'{name}_min'] = np.min(values)\n",
    "            features[f'{name}_max'] = np.max(values)\n",
    "\n",
    "    tid = tid_from_path(path)\n",
    "    features = pd.Series(dtype=np.float32, name=tid)\n",
    "    \n",
    "    y, sr = librosa.load(path)\n",
    "    # print(f'y: {y}\\nsr: {sr}')\n",
    "\n",
    "    # Tempo and Beats\n",
    "    tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    # print(f'tempo: {tempo}\\nbeats({len(beats)}):\\n{beats}')\n",
    "    features['tempo'] = tempo\n",
    "    feature_stat('beats', beats)\n",
    "\n",
    "    stft = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
    "    rms = librosa.feature.rms(S=stft)\n",
    "    feature_stat('rms', rms)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_names = ['_mean', '_std', '_median', '_min', '_max']\n",
    "feature_names = ['beats', 'rms']\n",
    "col_names = ['tempo']\n",
    "col_names = col_names + [f+stat for f in feature_names for stat in stat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More than usable CPUs to be CPU bound, not I/O bound. Beware memory.\n",
    "# nb_workers = int(1.5 * len(os.sched_getaffinity(0))) # only in ceratin os\n",
    "nb_workers = int(os.cpu_count())\n",
    "\n",
    "print(f'Working with {nb_workers} processes.')\n",
    "\n",
    "pool = multiprocessing.Pool(nb_workers)\n",
    "\n",
    "\n",
    "audio_paths = get_all_audio_paths(fma_small_path)\n",
    "\n",
    "# audios that are not able to load\n",
    "audio_paths.remove('data/fma_small/133/133297.mp3')\n",
    "audio_paths.remove('data/fma_small/099/099134.mp3')\n",
    "audio_paths.remove('data/fma_small/108/108925.mp3')\n",
    "\n",
    "# remove tracks that are already computed \n",
    "# bf = pd.read_csv(f'{data_path}/beats_features.csv', index_col=0)\n",
    "# print(f'start with {len(audio_paths)} tracks')\n",
    "# tids = ['{:06d}'.format(i) for i in bf.index]\n",
    "# for path in [f'{fma_small_path}/{i[0:3]}/{i}.mp3' for i in tids]:\n",
    "#     if path in audio_paths:\n",
    "#         audio_paths.remove(path)\n",
    "#     else:\n",
    "#         print(f'{path} not in.')\n",
    "# print(f'end with {len(audio_paths)} tracks')\n",
    "\n",
    "it = pool.imap_unordered(compute_beats_features, audio_paths)\n",
    "beats_features = pd.DataFrame(columns=col_names)\n",
    "\n",
    "for i, row in enumerate(tqdm(it, total=len(audio_paths))):\n",
    "    beats_features.loc[row.name] = row\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        beats_features.to_csv(f'{data_path}/beats_features_{datetime.now().strftime(\"%H:%M\")}.csv')\n",
    "\n",
    "beats_features.to_csv(f'{data_path}/beats_features.csv')\n"
   ]
  },
  {
   "source": [
    "# Beats Nearest Neighbor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beats_features = pd.read_csv(f'{data_path}/beats_features.csv', index_col=0)\n",
    "\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(beats_features)\n",
    "\n",
    "beats_i_to_id = beats_features.index\n",
    "with open(f'{data_path}/beats_i_to_id.pkl', 'wb') as f:\n",
    "    pickle.dump(beats_i_to_id, f)\n",
    "\n",
    "beats_nbrs = NearestNeighbors(n_neighbors=11, algorithm='auto').fit(beats_features)\n",
    "with open(f'{data_path}/beats_features_nn.pkl', 'wb') as f:\n",
    "    pickle.dump(beats_nbrs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = 121346\n",
    "audio_feature = beats_features[beats_features.index == tid]\n",
    "distances, indices = beats_nbrs.kneighbors(audio_feature)\n",
    "print(audio_feature.index)\n",
    "print([str(e) for e in beats_i_to_id[indices[0]]])\n",
    "sns.lineplot(x=[str(e) for e in beats_i_to_id[indices[0]]], y=distances[0])\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('distance')"
   ]
  },
  {
   "source": [
    "# Timbre Feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fma_load(f'{data_path}/features_small.csv')\n",
    "tracks = fma_load(f'{data_path}/tracks_small.csv')\n",
    "\n",
    "# train = tracks['set', 'split'] == 'training'\n",
    "# test = tracks['set', 'split'] == 'test'\n",
    "\n",
    "# y_train = tracks.loc[train, ('track', 'genre_top')]\n",
    "# y_test = tracks.loc[test, ('track', 'genre_top')]\n",
    "\n",
    "# X_train = features.loc[train]\n",
    "# # X_test = features.loc[test]\n",
    "\n",
    "timbre_features = features['mfcc']\n",
    "\n",
    "# print(f'{y_train.size} training examples, {y_test.size} testing examples')\n",
    "# print(f'{X_train.shape[1]} features, {np.unique(y_train).size} classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timbre_i_to_id = timbre_features.index\n",
    "\n",
    "scaler = skl.preprocessing.StandardScaler(copy=False)\n",
    "scaler.fit_transform(timbre_features)\n",
    "\n",
    "with open(f'{data_path}/timbre_i_to_id.pkl', 'wb') as f:\n",
    "    pickle.dump(timbre_i_to_id, f)\n",
    "\n",
    "timbre_nbrs = NearestNeighbors(n_neighbors=11, algorithm='auto').fit(timbre_features)\n",
    "with open(f'{data_path}/timbre_features_nn.pkl', 'wb') as f:\n",
    "    pickle.dump(timbre_nbrs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = 121346\n",
    "audio_feature = timbre_features[timbre_features.index == tid]\n",
    "distances, indices = timbre_nbrs.kneighbors(audio_feature)\n",
    "print(audio_feature.index)\n",
    "print([str(e) for e in timbre_i_to_id[indices[0]]])\n",
    "sns.lineplot(x=[str(e) for e in timbre_i_to_id[indices[0]]], y=distances[0])\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}